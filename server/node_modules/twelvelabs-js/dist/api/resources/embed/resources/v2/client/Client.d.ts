/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../../../environments";
import * as core from "../../../../../../core";
import * as TwelvelabsApi from "../../../../../index";
import { Tasks } from "../resources/tasks/client/Client";
export declare namespace V2 {
    interface Options {
        environment?: core.Supplier<environments.TwelvelabsApiEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string | undefined>;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}
export declare class V2 {
    protected readonly _options: V2.Options;
    protected _tasks: Tasks | undefined;
    constructor(_options?: V2.Options);
    get tasks(): Tasks;
    /**
     * This endpoint synchronously creates embeddings for multimodal content and returns the results immediately in the response.
     *
     * <Note title="Note">
     *   This method only supports Marengo version 3.0 or newer.
     * </Note>
     *
     * **When to use this endpoint**:
     * - Create embeddings for text, images, audio, or video content
     * - Get immediate results without waiting for background processing
     * - Process audio or video content up to 10 minutes in duration
     *
     * **Do not use this endpoint for**:
     * - Audio or video content longer than 10 minutes. Use the [`POST`](/v1.3/api-reference/create-embeddings-v2/create-async-embedding-task) method of the `/embed-v2/tasks` endpoint instead.
     *
     * <Accordion title="Input requirements">
     *   **Text**:
     *   - Maximum length: 500 tokens
     *
     *   **Images**:
     *   - Formats: JPEG, PNG
     *   - Minimum size: 128x128 pixels
     *   - Maximum file size: 5 MB
     *
     *   **Audio and video**:
     *   - Maximum duration: 10 minutes
     *   - Maximum file size for base64 encoded strings: 36 MB
     *   - Audio formats: WAV (uncompressed), MP3 (lossy), FLAC (lossless)
     *   - Video formats: [FFmpeg supported formats](https://ffmpeg.org/ffmpeg-formats.html)
     *   - Video resolution: 360x360 to 3840x2160 pixels
     *   - Aspect ratio: Between 1:1 and 1:2.4, or between 2.4:1 and 1:1
     * </Accordion>
     *
     * @param {TwelvelabsApi.embed.CreateEmbeddingsRequest} request
     * @param {V2.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link TwelvelabsApi.BadRequestError}
     * @throws {@link TwelvelabsApi.TooManyRequestsError}
     * @throws {@link TwelvelabsApi.InternalServerError}
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "text",
     *         modelName: "marengo3.0",
     *         text: {
     *             inputText: "man walking a dog"
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "image",
     *         modelName: "marengo3.0",
     *         image: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/folder/dog.jpg"
     *             }
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "text_image",
     *         modelName: "marengo3.0",
     *         textImage: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/folder/dog.jpg"
     *             },
     *             inputText: "man walking a dog"
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "image",
     *         modelName: "marengo3.0",
     *         image: {
     *             mediaSource: {
     *                 assetId: "1234567890"
     *             }
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "audio",
     *         modelName: "marengo3.0",
     *         audio: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/audio/a.wav"
     *             },
     *             startSec: 0,
     *             endSec: 6,
     *             segmentation: {
     *                 strategy: "fixed",
     *                 fixed: {
     *                     durationSec: 6
     *                 }
     *             },
     *             embeddingOption: ["audio", "transcription"],
     *             embeddingScope: ["clip", "asset"]
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "video",
     *         modelName: "marengo3.0",
     *         video: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/video/clip.mp4"
     *             },
     *             startSec: 0,
     *             endSec: 12,
     *             segmentation: {
     *                 strategy: "dynamic",
     *                 dynamic: {
     *                     minDurationSec: 4
     *                 }
     *             },
     *             embeddingOption: ["visual", "audio", "transcription"],
     *             embeddingScope: ["clip", "asset"]
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "video",
     *         modelName: "marengo3.0",
     *         video: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/video/simple.mp4"
     *             }
     *         }
     *     })
     *
     * @example
     *     await client.embed.v2.create({
     *         inputType: "audio",
     *         modelName: "marengo3.0",
     *         audio: {
     *             mediaSource: {
     *                 url: "https://user-bucket.com/audio/speech.wav"
     *             },
     *             embeddingOption: ["transcription"],
     *             embeddingScope: ["asset"]
     *         }
     *     })
     */
    create(request: TwelvelabsApi.embed.CreateEmbeddingsRequest, requestOptions?: V2.RequestOptions): core.HttpResponsePromise<TwelvelabsApi.EmbeddingSuccessResponse>;
    private __create;
    protected _getCustomAuthorizationHeaders(): Promise<{
        "x-api-key": string | undefined;
    }>;
}
