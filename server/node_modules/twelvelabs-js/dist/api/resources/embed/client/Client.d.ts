/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as TwelvelabsApi from "../../../index";
import { Tasks } from "../resources/tasks/client/Client";
import { V2 } from "../resources/v2/client/Client";
export declare namespace Embed {
    interface Options {
        environment?: core.Supplier<environments.TwelvelabsApiEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        apiKey?: core.Supplier<string | undefined>;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Additional headers to include in the request. */
        headers?: Record<string, string>;
    }
}
export declare class Embed {
    protected readonly _options: Embed.Options;
    protected _tasks: Tasks | undefined;
    protected _v2: V2 | undefined;
    constructor(_options?: Embed.Options);
    get tasks(): Tasks;
    get v2(): V2;
    /**
     * <Note title="Note">
     *   This endpoint will be deprecated in a future version. Migrate to the [Embed API v2](/v1.3/api-reference/create-embeddings-v2) for continued support and access to new features.
     * </Note>
     *
     * This method creates embeddings for text, image, and audio content.
     *
     * Ensure your media files meet the following requirements:
     * - [Audio files](/v1.3/docs/concepts/models/marengo#audio-requirements).
     * - [Image files](/v1.3/docs/concepts/models/marengo#image-requirements).
     *
     * Parameters for embeddings:
     * - **Common parameters**:
     *   - `model_name`: The video understanding model you want to use. Example: "marengo3.0".
     * - **Text embeddings**:
     *   - `text`: Text for which to create an embedding.
     * - **Image embeddings**:
     *   Provide one of the following:
     *   - `image_url`: Publicly accessible URL of your image file.
     *   - `image_file`:  Local image file.
     * - **Audio embeddings**:
     *   Provide one of the following:
     *   - `audio_url`: Publicly accessible URL of your audio file.
     *   - `audio_file`: Local audio file.
     *
     * <Note title="Notes">
     * - The Marengo video understanding model generates embeddings for all modalities in the same latent space. This shared space enables any-to-any searches across different types of content.
     * - You can create multiple types of embeddings in a single API call.
     * - Audio embeddings combine generic sound and human speech in a single embedding. For videos with transcriptions, you can retrieve transcriptions and then [create text embeddings](/v1.3/api-reference/create-embeddings-v1/text-image-audio-embeddings/create-text-image-audio-embeddings) from these transcriptions.
     * </Note>
     *
     * @param {TwelvelabsApi.EmbedCreateRequest} request
     * @param {Embed.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link TwelvelabsApi.BadRequestError}
     *
     * @example
     *     await client.embed.create({
     *         modelName: "model_name"
     *     })
     */
    create(request: TwelvelabsApi.EmbedCreateRequest, requestOptions?: Embed.RequestOptions): core.HttpResponsePromise<TwelvelabsApi.EmbeddingResponse>;
    private __create;
    protected _getCustomAuthorizationHeaders(): Promise<{
        "x-api-key": string | undefined;
    }>;
}
