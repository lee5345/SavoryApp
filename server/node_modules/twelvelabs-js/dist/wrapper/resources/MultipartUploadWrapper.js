"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || (function () {
    var ownKeys = function(o) {
        ownKeys = Object.getOwnPropertyNames || function (o) {
            var ar = [];
            for (var k in o) if (Object.prototype.hasOwnProperty.call(o, k)) ar[ar.length] = k;
            return ar;
        };
        return ownKeys(o);
    };
    return function (mod) {
        if (mod && mod.__esModule) return mod;
        var result = {};
        if (mod != null) for (var k = ownKeys(mod), i = 0; i < k.length; i++) if (k[i] !== "default") __createBinding(result, mod, k[i]);
        __setModuleDefault(result, mod);
        return result;
    };
})();
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.MultipartUploadWrapper = exports.UploadError = void 0;
const fs = __importStar(require("fs"));
const path = __importStar(require("path"));
const os = __importStar(require("os"));
const Client_1 = require("../../api/resources/multipartUpload/client/Client");
/**
 * Custom exception for upload-related errors.
 */
class UploadError extends Error {
    constructor(message, chunkIndex, originalError) {
        super(message);
        this.name = "UploadError";
        this.chunkIndex = chunkIndex;
        this.originalError = originalError;
    }
}
exports.UploadError = UploadError;
/**
 * Wrapper for the MultipartUpload client that adds high-level upload functionality.
 */
class MultipartUploadWrapper extends Client_1.MultipartUpload {
    constructor(options) {
        super(options);
    }
    /**
     * Upload a file using multipart upload with automatic chunking and progress tracking.
     *
     * @param filePath - Path to the file to upload.
     * @param options - Upload configuration options.
     * @returns A promise that resolves to the upload result.
     *
     * @example
     * ```typescript
     * import { TwelveLabs } from "twelvelabs";
     *
     * const client = new TwelveLabs({
     *     apiKey: "YOUR_API_KEY",
     * });
     *
     * // Simple upload
     * const result = await client.multipartUpload.uploadFile("video.mp4");
     * console.log(`Asset ID: ${result.assetId}`);
     * console.log(`Asset URL: ${result.assetUrl}`);
     *
     * // Upload with progress tracking
     * const progressCallback = (progress: UploadProgress) => {
     *     console.log(`Progress: ${progress.percentage.toFixed(1)}% (${progress.completedChunks}/${progress.totalChunks} chunks)`);
     * };
     *
     * const result = await client.multipartUpload.uploadFile("large_video.mp4", {
     *     filename: "my-video.mp4",
     *     progressCallback,
     *     batchSize: 5
     * });
     * console.log(`Upload completed! Asset ID: ${result.assetId}`);
     * ```
     */
    uploadFile(filePath_1) {
        return __awaiter(this, arguments, void 0, function* (filePath, options = {}) {
            const { filename = path.basename(filePath), fileType = "video", batchSize = 10, maxWorkers = 5, progressCallback, maxRetries = 3, retryDelay = 1.0, requestOptions, } = options;
            if (!fs.existsSync(filePath)) {
                throw new Error(`File not found: ${filePath}`);
            }
            const totalSize = fs.statSync(filePath).size;
            let chunkFiles = [];
            try {
                console.log(`Creating upload session for ${filename} (${totalSize.toLocaleString()} bytes)`);
                // Step 1: Create upload session
                const uploadSession = yield this.create({
                    filename,
                    totalSize,
                }, requestOptions);
                if (!uploadSession.uploadId || !uploadSession.chunkSize) {
                    throw new UploadError("Invalid upload session response: missing uploadId or chunkSize");
                }
                const uploadId = uploadSession.uploadId;
                const chunkSize = uploadSession.chunkSize;
                console.log(`Upload session created: ${uploadId} (chunk size: ${chunkSize.toLocaleString()} bytes)`);
                // Step 2: Split file into chunks
                chunkFiles = yield this._splitFile(filePath, chunkSize);
                const totalChunks = chunkFiles.length;
                console.log(`File split into ${totalChunks} chunks`);
                if (totalChunks === 0) {
                    throw new UploadError("No chunks created from file");
                }
                // Step 3: Upload chunks in batches
                const currentUrls = {};
                if (uploadSession.uploadUrls) {
                    for (const url of uploadSession.uploadUrls) {
                        if (url.chunkIndex && url.url) {
                            currentUrls[url.chunkIndex] = url.url;
                        }
                    }
                }
                let completedChunksCount = 0;
                for (let batchStart = 0; batchStart < totalChunks; batchStart += batchSize) {
                    const batchEnd = Math.min(batchStart + batchSize, totalChunks);
                    const batchChunkFiles = chunkFiles.slice(batchStart, batchEnd);
                    const batchIndices = Array.from({ length: batchEnd - batchStart }, (_, i) => batchStart + i + 1); // 1-based indexing
                    // Ensure we have URLs for all chunks in this batch
                    const missingUrls = batchIndices.filter((idx) => !(idx in currentUrls));
                    if (missingUrls.length > 0) {
                        const minChunk = Math.min(...missingUrls);
                        const maxChunk = Math.max(...missingUrls);
                        console.log(`Fetching URLs for chunks ${minChunk}-${maxChunk} (${missingUrls.length} missing)`);
                        const start = minChunk;
                        const count = maxChunk - minChunk + 1;
                        const additionalUrls = yield this.getAdditionalPresignedUrls(uploadId, {
                            start,
                            count,
                        }, requestOptions);
                        if (additionalUrls.uploadUrls) {
                            for (const urlInfo of additionalUrls.uploadUrls) {
                                if (urlInfo.chunkIndex && urlInfo.url && missingUrls.includes(urlInfo.chunkIndex)) {
                                    currentUrls[urlInfo.chunkIndex] = urlInfo.url;
                                }
                            }
                        }
                    }
                    // Upload batch chunks in parallel with retry logic
                    const batchCompletedChunks = yield this._uploadChunkBatchWithRetry(batchChunkFiles, batchIndices, currentUrls, maxWorkers, maxRetries, retryDelay);
                    // Report completed batch
                    const result = yield this.reportChunkBatch(uploadId, {
                        completedChunks: batchCompletedChunks,
                    }, requestOptions);
                    completedChunksCount += batchCompletedChunks.length;
                    // Update progress
                    if (progressCallback) {
                        const progress = {
                            totalChunks,
                            completedChunks: completedChunksCount,
                            percentage: (completedChunksCount / totalChunks) * 100,
                            status: "uploading",
                        };
                        progressCallback(progress);
                    }
                    // Check if upload is complete
                    if (result.url) {
                        console.log(`Upload completed successfully! Asset ID: ${uploadSession.assetId}`);
                        return {
                            assetId: uploadSession.assetId || "",
                            assetUrl: result.url,
                        };
                    }
                }
                // All chunks have been uploaded and reported
                console.log(`Upload completed successfully! Asset ID: ${uploadSession.assetId}`);
                return {
                    assetId: uploadSession.assetId || "",
                    assetUrl: "", // URL will be available after processing
                };
            }
            catch (error) {
                if (error instanceof UploadError) {
                    throw error;
                }
                throw new UploadError(`Upload failed: ${error instanceof Error ? error.message : String(error)}`, undefined, error instanceof Error ? error : undefined);
            }
            finally {
                // Cleanup temporary files
                if (chunkFiles.length > 0) {
                    try {
                        yield this._cleanupChunks(chunkFiles);
                    }
                    catch (error) {
                        console.warn(`Failed to cleanup chunk files: ${error}`);
                    }
                }
            }
        });
    }
    /**
     * Wait for a multipart upload to complete by periodically checking its status.
     *
     * @param uploadId - The unique identifier of the upload session.
     * @param options - Wait configuration options.
     * @returns A promise that resolves to the final upload status.
     *
     * @example
     * ```typescript
     * import { TwelveLabs } from "twelvelabs";
     *
     * const client = new TwelveLabs({
     *     apiKey: "YOUR_API_KEY",
     * });
     *
     * // Start upload in background
     * const uploadId = "507f1f77bcf86cd799439011";
     *
     * // Wait for completion with timeout
     * const completedUpload = await client.multipartUpload.waitForUploadCompletion(uploadId, {
     *     sleepInterval: 10.0,
     *     maxWaitTime: 3600.0, // 1 hour timeout
     * });
     * ```
     */
    waitForUploadCompletion(uploadId_1) {
        return __awaiter(this, arguments, void 0, function* (uploadId, options = {}) {
            var _a, e_1, _b, _c;
            var _d, _e;
            const { sleepInterval = 5.0, maxWaitTime, callback, requestOptions } = options;
            if (sleepInterval <= 0) {
                throw new Error("sleepInterval must be greater than 0");
            }
            const startTime = Date.now();
            while (true) {
                try {
                    // Get chunk status
                    const chunkStatusPage = yield this.getStatus(uploadId, {}, requestOptions);
                    const chunkStatusItems = [];
                    try {
                        // Collect all chunks from paginated response
                        for (var _f = true, chunkStatusPage_1 = (e_1 = void 0, __asyncValues(chunkStatusPage)), chunkStatusPage_1_1; chunkStatusPage_1_1 = yield chunkStatusPage_1.next(), _a = chunkStatusPage_1_1.done, !_a; _f = true) {
                            _c = chunkStatusPage_1_1.value;
                            _f = false;
                            const chunk = _c;
                            chunkStatusItems.push(chunk);
                        }
                    }
                    catch (e_1_1) { e_1 = { error: e_1_1 }; }
                    finally {
                        try {
                            if (!_f && !_a && (_b = chunkStatusPage_1.return)) yield _b.call(chunkStatusPage_1);
                        }
                        finally { if (e_1) throw e_1.error; }
                    }
                    let completedChunks = 0;
                    let totalChunks = 0;
                    const failedChunks = [];
                    // Count completed and failed chunks
                    for (const chunk of chunkStatusItems) {
                        totalChunks += 1;
                        if (((_d = chunk.status) === null || _d === void 0 ? void 0 : _d.valueOf()) === "completed") {
                            completedChunks += 1;
                        }
                        else if (((_e = chunk.status) === null || _e === void 0 ? void 0 : _e.valueOf()) === "failed") {
                            if (chunk.index) {
                                failedChunks.push(chunk.index);
                            }
                        }
                    }
                    // Check for failed chunks
                    if (failedChunks.length > 0) {
                        throw new UploadError(`Chunks ${failedChunks.join(", ")} failed to upload`);
                    }
                    // Create status object
                    const status = {
                        status: completedChunks === totalChunks ? "completed" : "in_progress",
                        completedChunks,
                        totalChunks,
                    };
                    // Call callback if provided
                    if (callback) {
                        callback(status);
                    }
                    // Check if complete
                    if (completedChunks === totalChunks) {
                        return status;
                    }
                    // Check timeout
                    if (maxWaitTime && Date.now() - startTime > maxWaitTime * 1000) {
                        throw new UploadError(`Upload timed out after ${maxWaitTime} seconds`);
                    }
                    yield this._sleep(sleepInterval * 1000);
                }
                catch (error) {
                    if (error instanceof UploadError) {
                        throw error;
                    }
                    console.warn(`Error checking upload status: ${error}`);
                    yield this._sleep(sleepInterval * 1000);
                }
            }
        });
    }
    /**
     * Split file into chunks and return list of chunk file paths.
     */
    _splitFile(filePath, chunkSize) {
        return __awaiter(this, void 0, void 0, function* () {
            const chunkFiles = [];
            const chunkDir = path.join(os.tmpdir(), `${path.basename(filePath, path.extname(filePath))}_chunks_${Date.now()}`);
            try {
                yield fs.promises.mkdir(chunkDir, { recursive: true });
                const fileHandle = yield fs.promises.open(filePath, "r");
                let chunkNum = 1;
                let position = 0;
                try {
                    while (true) {
                        const buffer = Buffer.alloc(chunkSize);
                        const { bytesRead } = yield fileHandle.read(buffer, 0, chunkSize, position);
                        if (bytesRead === 0) {
                            break;
                        }
                        const chunkFile = path.join(chunkDir, `chunk_${chunkNum.toString().padStart(4, "0")}`);
                        yield fs.promises.writeFile(chunkFile, buffer.subarray(0, bytesRead));
                        chunkFiles.push(chunkFile);
                        chunkNum++;
                        position += bytesRead;
                    }
                }
                finally {
                    yield fileHandle.close();
                }
            }
            catch (error) {
                // Clean up any partial chunks on error
                yield this._cleanupChunks(chunkFiles);
                throw new UploadError(`Failed to split file into chunks: ${error instanceof Error ? error.message : String(error)}`, undefined, error instanceof Error ? error : undefined);
            }
            return chunkFiles;
        });
    }
    /**
     * Upload a single chunk to S3 and return ETag.
     */
    _uploadChunkToS3(chunkFile, presignedUrl) {
        return __awaiter(this, void 0, void 0, function* () {
            var _a;
            try {
                const chunkData = yield fs.promises.readFile(chunkFile);
                const response = yield fetch(presignedUrl, {
                    method: "PUT",
                    body: chunkData,
                    headers: {
                        "Content-Type": "application/octet-stream",
                    },
                });
                if (!response.ok) {
                    throw new Error(`HTTP ${response.status}: ${response.statusText}`);
                }
                const etag = (_a = response.headers.get("ETag")) === null || _a === void 0 ? void 0 : _a.replace(/"/g, "");
                if (!etag) {
                    throw new UploadError("No ETag received from S3 upload");
                }
                return etag;
            }
            catch (error) {
                throw new UploadError(`Failed to upload chunk: ${error instanceof Error ? error.message : String(error)}`, undefined, error instanceof Error ? error : undefined);
            }
        });
    }
    /**
     * Upload a batch of chunks in parallel with retry logic.
     */
    _uploadChunkBatchWithRetry(chunkFiles, chunkIndices, presignedUrls, maxWorkers, maxRetries, retryDelay) {
        return __awaiter(this, void 0, void 0, function* () {
            const completedChunks = [];
            const actualMaxWorkers = Math.min(chunkFiles.length, maxWorkers);
            const uploadChunkWithRetry = (chunkFile, chunkIndex) => __awaiter(this, void 0, void 0, function* () {
                const presignedUrl = presignedUrls[chunkIndex];
                let lastError;
                for (let attempt = 0; attempt <= maxRetries; attempt++) {
                    try {
                        const etag = yield this._uploadChunkToS3(chunkFile, presignedUrl);
                        const chunkSizeBytes = (yield fs.promises.stat(chunkFile)).size;
                        return {
                            chunkIndex,
                            proof: etag,
                            proofType: "etag",
                            chunkSize: chunkSizeBytes,
                        };
                    }
                    catch (error) {
                        lastError = error instanceof Error ? error : new Error(String(error));
                        if (attempt < maxRetries) {
                            console.warn(`Chunk ${chunkIndex} upload failed (attempt ${attempt + 1}/${maxRetries + 1}): ${lastError.message}`);
                            yield this._sleep(retryDelay * 1000 * Math.pow(2, attempt)); // Exponential backoff
                        }
                        else {
                            console.error(`Chunk ${chunkIndex} upload failed after ${maxRetries + 1} attempts`);
                        }
                    }
                }
                throw new UploadError(`Chunk ${chunkIndex} upload failed after ${maxRetries + 1} attempts`, chunkIndex, lastError);
            });
            // Create promises for all chunks
            const uploadPromises = chunkFiles.map((chunkFile, i) => {
                const chunkIndex = chunkIndices[i];
                return uploadChunkWithRetry(chunkFile, chunkIndex);
            });
            // Process uploads with concurrency limit
            const results = yield this._processConcurrently(uploadPromises, actualMaxWorkers);
            for (const result of results) {
                if (result.status === "fulfilled") {
                    completedChunks.push(result.value);
                }
                else {
                    const error = result.reason;
                    if (error instanceof UploadError) {
                        throw error;
                    }
                    throw new UploadError(`Chunk upload failed: ${error instanceof Error ? error.message : String(error)}`, undefined, error instanceof Error ? error : undefined);
                }
            }
            return completedChunks;
        });
    }
    /**
     * Process promises with concurrency limit.
     */
    _processConcurrently(promises, maxConcurrency) {
        return __awaiter(this, void 0, void 0, function* () {
            const results = [];
            for (let i = 0; i < promises.length; i += maxConcurrency) {
                const batch = promises.slice(i, i + maxConcurrency);
                const batchResults = yield Promise.allSettled(batch);
                results.push(...batchResults);
            }
            return results;
        });
    }
    /**
     * Clean up temporary chunk files.
     */
    _cleanupChunks(chunkFiles) {
        return __awaiter(this, void 0, void 0, function* () {
            if (chunkFiles.length === 0) {
                return;
            }
            let chunkDir;
            for (const chunkFile of chunkFiles) {
                try {
                    if (fs.existsSync(chunkFile)) {
                        yield fs.promises.unlink(chunkFile);
                    }
                    if (!chunkDir) {
                        chunkDir = path.dirname(chunkFile);
                    }
                }
                catch (error) {
                    console.warn(`Failed to delete chunk file ${chunkFile}: ${error}`);
                }
            }
            // Remove chunk directory if empty
            if (chunkDir && fs.existsSync(chunkDir)) {
                try {
                    yield fs.promises.rmdir(chunkDir);
                }
                catch (_a) {
                    // Directory not empty or other error, ignore
                }
            }
        });
    }
    /**
     * Sleep for the specified number of milliseconds.
     */
    _sleep(ms) {
        return new Promise((resolve) => setTimeout(resolve, ms));
    }
}
exports.MultipartUploadWrapper = MultipartUploadWrapper;
